{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RGBCNN.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"3L2YSIc843Nj","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K4mUqkVh5LfM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"outputId":"9918d0b7-8797-4fb7-b862-4d8170a4c2aa","executionInfo":{"status":"ok","timestamp":1577194821593,"user_tz":-120,"elapsed":32727,"user":{"displayName":"Reem Tarek","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mD_WR0W8rnVJGe-9k8WJJd0C7da2USCpLW5O7AIJA=s64","userId":"08554237500380784968"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VezNsuy95VbM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":185},"outputId":"8f85d356-a7be-4c13-ec42-0862a1495705","executionInfo":{"status":"ok","timestamp":1577194835046,"user_tz":-120,"elapsed":13441,"user":{"displayName":"Reem Tarek","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mD_WR0W8rnVJGe-9k8WJJd0C7da2USCpLW5O7AIJA=s64","userId":"08554237500380784968"}}},"source":["!pip install scipy==1.1.0"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting scipy==1.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/0b/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2MB)\n","\u001b[K     |████████████████████████████████| 31.2MB 140kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.17.4)\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: scipy\n","  Found existing installation: scipy 1.3.3\n","    Uninstalling scipy-1.3.3:\n","      Successfully uninstalled scipy-1.3.3\n","Successfully installed scipy-1.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Th2Hfh_B5dN0","colab_type":"code","colab":{}},"source":["import os\n","import numpy as np\n","from os import listdir\n","from scipy.misc import imread, imresize\n","from keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","\n","# Settings:\n","img_size = 64\n","grayscale_images = False\n","num_class = 10\n","test_size = 0.2\n","\n","\n","def get_img(data_path):\n","    # Getting image array from path:\n","    img = imread(data_path, flatten=grayscale_images)\n","    img = imresize(img, (img_size, img_size, 1 if grayscale_images else 3))\n","    \n","    return img\n","\n","def get_dataset(dataset_path='drive/My Drive/Sign-Language-Digits-Dataset-master (1)/Dataset (1)'):\n","    # Getting all data from data path:\n","    try:\n","        X = np.load('npy_dataset/X.npy')\n","        Y = np.load('npy_dataset/Y.npy')\n","    except:\n","        labels = listdir(dataset_path) # Geting labels\n","        X = []\n","        Y = []\n","        for i, label in enumerate(labels):\n","            datas_path = dataset_path+'/'+label\n","            for data in listdir(datas_path):\n","                img = get_img(datas_path+'/'+data)\n","                X.append(img)\n","                Y.append(i)\n","        # Create dateset:\n","        X -= np.mean(X)\n","        X = np.array(X).astype('float32')/255.\n","        Y = np.array(Y).astype('float32')\n","        Y = to_categorical(Y, num_class)\n","        if not os.path.exists('npy_dataset/'):\n","            os.makedirs('npy_dataset/')\n","        np.save('npy_dataset/X.npy', X)\n","        np.save('npy_dataset/Y.npy', Y)\n","    X, X_test, Y, Y_test = train_test_split(X, Y, test_size=test_size, random_state=42)\n","    return X, X_test, Y, Y_test\n","\n","if __name__ == '__main__':\n","    get_dataset()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V1XsgbI876et","colab_type":"code","colab":{}},"source":[" import numpy as np\n"," import matplotlib.pyplot as plt\n"," X = np.load('npy_dataset/X.npy') \n"," Y = np.load('npy_dataset/Y.npy') \n","# f, ax = plt.subplots(2, 2, figsize=(15, 10))\n","# sample = [290, 1000, 1800, 650]\n","# for i in range(0, 4):\n","#     ax[i//2, i%2].imshow(X[sample[i]].reshape(64, 64,3))\n","#     ax[i//2, i%2].axis('on')\n","# plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5fgE3QHt8Dla","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"edaf1303-b3d7-4c96-b313-88ee2931ac96","executionInfo":{"status":"ok","timestamp":1577197567486,"user_tz":-120,"elapsed":596,"user":{"displayName":"Reem Tarek","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mD_WR0W8rnVJGe-9k8WJJd0C7da2USCpLW5O7AIJA=s64","userId":"08554237500380784968"}}},"source":["X.shape\n","X = X.reshape(X.shape[0], 64, 64, 3)\n","X.shape\n","X_train=[]\n","X_test=[]\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=None)\n","print(X_train.shape[0])"],"execution_count":10,"outputs":[{"output_type":"stream","text":["1649\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ByRaE9Fe8Kjr","colab_type":"code","colab":{}},"source":["from keras.models import Sequential, Model\n","from keras.layers import Dense, Dropout, Flatten, Input\n","from keras.layers.convolutional import Conv2D, MaxPooling2D\n","from keras import backend as K\n","\n","def recall_m(y_true, y_pred):\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","        recall = true_positives / (possible_positives + K.epsilon())\n","        return recall\n","\n","def precision_m(y_true, y_pred):\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","        precision = true_positives / (predicted_positives + K.epsilon())\n","        return precision\n","\n","def f1_m(y_true, y_pred):\n","    precision = precision_m(y_true, y_pred)\n","    recall = recall_m(y_true, y_pred)\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B7kagc1T8Xau","colab_type":"code","colab":{}},"source":["def model1(X_train,y_train,X_test,y_test):\n","  model_input = Input(shape=(64, 64,3))\n","  feature = Conv2D(32, (3, 3), activation='relu', padding='same')(model_input)\n","  feature = MaxPooling2D(pool_size=(2, 2))(feature)    \n","  feature = Dropout(0.5)(feature)\n","    \n","  feature = Conv2D(32, (3, 3), activation='relu', padding='same')(feature)\n","  feature = Conv2D(16, (3, 3), activation='relu', padding='same')(feature)\n","\n","  feature = MaxPooling2D(pool_size=(2, 2))(feature)    \n","  feature = Dropout(0.5)(feature)\n","    \n","  feature = Conv2D(32, (3, 3), activation='relu', padding='same')(feature)       \n","  feature = MaxPooling2D(pool_size=(2, 2))(feature)    \n","  feature = MaxPooling2D(pool_size=(2, 2))(feature)    \n","\n","  feature = Dropout(0.5)(feature)\n","    \n","  feature = Flatten()(feature)\n","  feature = Dense(512, activation='relu')(feature)    \n","  feature = Dropout(0.5)(feature)\n","    \n","  output = Dense(10, activation='softmax')(feature)\n","    \n","  model = Model(inputs=model_input, outputs= output)\n","  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc',f1_m, precision_m, recall_m])\n","  model.summary()\n"," \n","  n_folds=4\n","\n","  for i in range(n_folds):\n","      print(\"Training on Fold: \",i+1)\n","      t_x, val_x, t_y, val_y = train_test_split(X_train, y_train, test_size=0.25, random_state = 7)\n","      model.fit(t_x, t_y, validation_data=(val_x, val_y), epochs=10, batch_size=32)\n","      model.evaluate(val_x, val_y)\n","\n","\n","     \n","  average=0\n","\n","  for i in range(len(X_test)):\n","   ypre=model.predict(X_test[i].reshape(1,64,64,3))\n","   if(ypre.any()==y_test[i].any()):\n","     average = average+1\n","  print(\"test predictions \",average/len(y_test))\n","  loss, accuracy, scores, pre, recall = model.evaluate(X_test, y_test)\n","\n","  return scores, pre, recall,average/len(y_test)\n","\n","  \n","def model2(X_train,y_train,X_test,y_test):\n","  model_input = Input(shape=(64, 64,3))\n","  features = Conv2D(64, (3, 3), activation='relu', padding='same')(model_input)\n","  features = MaxPooling2D(pool_size=(2, 2))(features)   \n","  features = MaxPooling2D(pool_size=(2, 2))(features)    \n"," \n","  features = Dropout(0.5)(features)\n","    \n","  features = Conv2D(64, (3, 3), activation='relu', padding='same')(features)\n","  features = Conv2D(64, (3, 3), activation='relu', padding='same')(features)\n","\n","  features = MaxPooling2D(pool_size=(2, 2))(features)    \n","  features = Dropout(0.5)(features)\n","    \n","  features = Flatten()(features)\n","  features = Dense(512, activation='relu')(features)    \n","  features = Dropout(0.5)(features)\n","    \n","  output = Dense(10, activation='softmax')(features)\n","    \n","  model = Model(inputs=model_input, outputs= output)\n","  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc',f1_m, precision_m, recall_m])\n","  model.summary()\n"," \n","  n_folds=4\n","\n","  for i in range(n_folds):\n","      print(\"Training on Fold: \",i+1)\n","      t_x, val_x, t_y, val_y = train_test_split(X_train, y_train, test_size=0.25, random_state = 7)\n","      model.fit(t_x, t_y, validation_data=(val_x, val_y), epochs=10, batch_size=32)\n","      model.evaluate(val_x, val_y)\n","  loss, accuracy, scores, pre, recall = model.evaluate(X_test, y_test)\n","  \n","     \n","  average=0\n","\n","  for i in range(len(X_test)):\n","   ypre=model.predict(X_test[i].reshape(1,64,64,3))\n","   if(ypre.any()==y_test[i].any()):\n","     average = average+1\n","  print(\"predictions \",average/len(y_test))\n","  return scores, pre, recall,average/len(y_test)\n","\n","def model3(X_train,y_train,X_test,y_test):\n","  model_input = Input(shape=(64, 64,3))\n","  features = Conv2D(16, (2, 2), activation='relu', padding='same')(model_input)\n","  features= MaxPooling2D(pool_size=(2, 2))(features)    \n","  features = Dropout(0.5)(features)\n","    \n","  features = Conv2D(32, (3, 3), activation='relu', padding='same')(features)\n","  features = MaxPooling2D(pool_size=(2, 2))(features)    \n","  features = Dropout(0.5)(features)\n","  features = Conv2D(64, (5, 5), activation='relu', padding='same')(features)\n","  features = MaxPooling2D(pool_size=(2, 2))(features)    \n","  features = Dropout(0.5)(features)\n","  features = Conv2D(128, (5, 5), activation='relu', padding='same')(features)\n","  features = MaxPooling2D(pool_size=(2, 2))(features)    \n","  features = Dropout(0.5)(features)\n","    \n","  features = Flatten()(features)\n","  features = Dense(512, activation='relu')(features)    \n","  features = Dropout(0.5)(features)\n","    \n","  output = Dense(10, activation='softmax')(features)\n","    \n","  model = Model(inputs=model_input, outputs= output)\n","  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc',f1_m, precision_m, recall_m])\n","  model.summary()\n"," \n","  n_folds=4\n","\n","  for i in range(n_folds):\n","      print(\"Training on Fold: \",i+1)\n","      t_x, val_x, t_y, val_y = train_test_split(X_train, y_train, test_size=0.25, random_state = 7)\n","      model.fit(t_x, t_y, validation_data=(val_x, val_y), epochs=10, batch_size=32)\n","      model.evaluate(val_x, val_y)\n","  loss, accuracy, scores, pre, recall = model.evaluate(X_test, y_test)\n","  \n","  average=0\n","\n","  for i in range(len(X_test)):\n","   ypre=model.predict(X_test[i].reshape(1,64,64,3))\n","   if(ypre.any()==y_test[i].any()):\n","     average = average+1\n","  print(\"predictions \",average/len(y_test))\n","   \n","  return scores, pre, recall,average/len(y_test)\n","def model4(X_train,y_train,X_test,y_test):\n","  model_input = Input(shape=(64, 64,3))\n","  features = Conv2D(128, (3, 3), activation='relu', padding='same')(model_input)\n","  features = MaxPooling2D(pool_size=(2, 2))(features)    \n","  features = Dropout(0.5)(features)\n","    \n","  features = Conv2D(128, (3, 3), activation='relu', padding='same')(features)\n","  features = MaxPooling2D(pool_size=(2, 2))(features)    \n","  features = Dropout(0.5)(features)    \n","  features = Flatten()(features)\n","  features = Dense(64, activation='relu')(features)    \n","  features = Dropout(0.5)(features)\n","    \n","  output = Dense(10, activation='softmax')(features)\n","    \n","  model = Model(inputs=model_input, outputs= output)\n","  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc',f1_m, precision_m, recall_m])\n","  model.summary()\n"," \n","  n_folds=4\n","\n","  for i in range(n_folds):\n","      print(\"Training on Fold: \",i+1)\n","      t_x, val_x, t_y, val_y = train_test_split(X_train, y_train, test_size=0.25, random_state = 7)\n","      history=model.fit(t_x, t_y, validation_data=(val_x, val_y), epochs=10, batch_size=32)\n","      model.evaluate(val_x, val_y) \n","  loss, accuracy, scores, pre, recall = model.evaluate(X_test, y_test)\n","  \n","     \n","  average=0\n","\n","  for i in range(len(X_test)):\n","   ypre=model.predict(X_test[i].reshape(1,64,64,3))\n","   if(ypre.any()==y_test[i].any()):\n","     average = average+1\n","  print(\"predictions \",average/len(y_test))\n","   \n","  return scores, pre, recall,average/len(y_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yCc2BOnE8atn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"48531f16-e9b3-4411-80a7-9a4db9ab11f5"},"source":["print(model1(X_train,y_train,X_test,y_test))\n","print(model2(X_train,y_train,X_test,y_test))\n","print(model3(X_train,y_train,X_test,y_test))\n","print(model4(X_train,y_train,X_test,y_test))\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"model_19\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_19 (InputLayer)        (None, 64, 64, 3)         0         \n","_________________________________________________________________\n","conv2d_65 (Conv2D)           (None, 64, 64, 32)        896       \n","_________________________________________________________________\n","max_pooling2d_65 (MaxPooling (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","dropout_70 (Dropout)         (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","conv2d_66 (Conv2D)           (None, 32, 32, 32)        9248      \n","_________________________________________________________________\n","conv2d_67 (Conv2D)           (None, 32, 32, 16)        4624      \n","_________________________________________________________________\n","max_pooling2d_66 (MaxPooling (None, 16, 16, 16)        0         \n","_________________________________________________________________\n","dropout_71 (Dropout)         (None, 16, 16, 16)        0         \n","_________________________________________________________________\n","conv2d_68 (Conv2D)           (None, 16, 16, 32)        4640      \n","_________________________________________________________________\n","max_pooling2d_67 (MaxPooling (None, 8, 8, 32)          0         \n","_________________________________________________________________\n","max_pooling2d_68 (MaxPooling (None, 4, 4, 32)          0         \n","_________________________________________________________________\n","dropout_72 (Dropout)         (None, 4, 4, 32)          0         \n","_________________________________________________________________\n","flatten_19 (Flatten)         (None, 512)               0         \n","_________________________________________________________________\n","dense_37 (Dense)             (None, 512)               262656    \n","_________________________________________________________________\n","dropout_73 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_38 (Dense)             (None, 10)                5130      \n","=================================================================\n","Total params: 287,194\n","Trainable params: 287,194\n","Non-trainable params: 0\n","_________________________________________________________________\n","Training on Fold:  1\n","Train on 1236 samples, validate on 413 samples\n","Epoch 1/10\n","1236/1236 [==============================] - 12s 10ms/step - loss: 2.2818 - acc: 0.1400 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 2.2109 - val_acc: 0.3366 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n","Epoch 2/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 1.8762 - acc: 0.3147 - f1_m: 0.1200 - precision_m: 0.4796 - recall_m: 0.0728 - val_loss: 1.6137 - val_acc: 0.5182 - val_f1_m: 0.0813 - val_precision_m: 0.6973 - val_recall_m: 0.0436\n","Epoch 3/10\n","1236/1236 [==============================] - 9s 8ms/step - loss: 1.3776 - acc: 0.5170 - f1_m: 0.4089 - precision_m: 0.7366 - recall_m: 0.2913 - val_loss: 1.1345 - val_acc: 0.6368 - val_f1_m: 0.4545 - val_precision_m: 0.9457 - val_recall_m: 0.3051\n","Epoch 4/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 1.1401 - acc: 0.5777 - f1_m: 0.5314 - precision_m: 0.7156 - recall_m: 0.4272 - val_loss: 0.9147 - val_acc: 0.7046 - val_f1_m: 0.6321 - val_precision_m: 0.8920 - val_recall_m: 0.4939\n","Epoch 5/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.9691 - acc: 0.6359 - f1_m: 0.6269 - precision_m: 0.7711 - recall_m: 0.5307 - val_loss: 0.9270 - val_acc: 0.7312 - val_f1_m: 0.6071 - val_precision_m: 0.9696 - val_recall_m: 0.4479\n","Epoch 6/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.9473 - acc: 0.6481 - f1_m: 0.6239 - precision_m: 0.7784 - recall_m: 0.5235 - val_loss: 0.7717 - val_acc: 0.7821 - val_f1_m: 0.6983 - val_precision_m: 0.9320 - val_recall_m: 0.5642\n","Epoch 7/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.7927 - acc: 0.7160 - f1_m: 0.7035 - precision_m: 0.8003 - recall_m: 0.6303 - val_loss: 0.7411 - val_acc: 0.7845 - val_f1_m: 0.7270 - val_precision_m: 0.9343 - val_recall_m: 0.5981\n","Epoch 8/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.7585 - acc: 0.7387 - f1_m: 0.7208 - precision_m: 0.8271 - recall_m: 0.6408 - val_loss: 0.6689 - val_acc: 0.8208 - val_f1_m: 0.7710 - val_precision_m: 0.9187 - val_recall_m: 0.6659\n","Epoch 9/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.7102 - acc: 0.7492 - f1_m: 0.7442 - precision_m: 0.8310 - recall_m: 0.6756 - val_loss: 0.6437 - val_acc: 0.8136 - val_f1_m: 0.7795 - val_precision_m: 0.9444 - val_recall_m: 0.6659\n","Epoch 10/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.6098 - acc: 0.7896 - f1_m: 0.7821 - precision_m: 0.8576 - recall_m: 0.7217 - val_loss: 0.5779 - val_acc: 0.8450 - val_f1_m: 0.8089 - val_precision_m: 0.9217 - val_recall_m: 0.7215\n","413/413 [==============================] - 1s 2ms/step\n","Training on Fold:  2\n","Train on 1236 samples, validate on 413 samples\n","Epoch 1/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.6254 - acc: 0.7937 - f1_m: 0.7847 - precision_m: 0.8578 - recall_m: 0.7257 - val_loss: 0.5939 - val_acc: 0.8475 - val_f1_m: 0.7980 - val_precision_m: 0.9525 - val_recall_m: 0.6877\n","Epoch 2/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.5648 - acc: 0.8018 - f1_m: 0.7893 - precision_m: 0.8504 - recall_m: 0.7387 - val_loss: 0.5573 - val_acc: 0.8305 - val_f1_m: 0.8081 - val_precision_m: 0.9251 - val_recall_m: 0.7191\n","Epoch 3/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.5420 - acc: 0.8034 - f1_m: 0.7877 - precision_m: 0.8513 - recall_m: 0.7346 - val_loss: 0.4453 - val_acc: 0.8862 - val_f1_m: 0.8552 - val_precision_m: 0.9315 - val_recall_m: 0.7918\n","Epoch 4/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.4904 - acc: 0.8188 - f1_m: 0.8150 - precision_m: 0.8665 - recall_m: 0.7710 - val_loss: 0.4490 - val_acc: 0.8935 - val_f1_m: 0.8574 - val_precision_m: 0.9411 - val_recall_m: 0.7893\n","Epoch 5/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.5005 - acc: 0.8293 - f1_m: 0.8250 - precision_m: 0.8711 - recall_m: 0.7848 - val_loss: 0.4780 - val_acc: 0.8935 - val_f1_m: 0.8496 - val_precision_m: 0.9680 - val_recall_m: 0.7579\n","Epoch 6/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.4441 - acc: 0.8455 - f1_m: 0.8435 - precision_m: 0.8831 - recall_m: 0.8091 - val_loss: 0.4291 - val_acc: 0.9104 - val_f1_m: 0.8673 - val_precision_m: 0.9471 - val_recall_m: 0.8015\n","Epoch 7/10\n","1236/1236 [==============================] - 9s 8ms/step - loss: 0.4688 - acc: 0.8414 - f1_m: 0.8404 - precision_m: 0.8821 - recall_m: 0.8034 - val_loss: 0.4465 - val_acc: 0.8765 - val_f1_m: 0.8459 - val_precision_m: 0.9490 - val_recall_m: 0.7651\n","Epoch 8/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.3852 - acc: 0.8665 - f1_m: 0.8694 - precision_m: 0.9012 - recall_m: 0.8406 - val_loss: 0.3458 - val_acc: 0.9322 - val_f1_m: 0.8993 - val_precision_m: 0.9536 - val_recall_m: 0.8523\n","Epoch 9/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.3802 - acc: 0.8730 - f1_m: 0.8744 - precision_m: 0.9047 - recall_m: 0.8471 - val_loss: 0.3493 - val_acc: 0.9007 - val_f1_m: 0.8991 - val_precision_m: 0.9406 - val_recall_m: 0.8620\n","Epoch 10/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.3648 - acc: 0.8673 - f1_m: 0.8691 - precision_m: 0.8957 - recall_m: 0.8447 - val_loss: 0.3081 - val_acc: 0.9274 - val_f1_m: 0.9165 - val_precision_m: 0.9528 - val_recall_m: 0.8838\n","413/413 [==============================] - 1s 2ms/step\n","Training on Fold:  3\n","Train on 1236 samples, validate on 413 samples\n","Epoch 1/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.3860 - acc: 0.8730 - f1_m: 0.8680 - precision_m: 0.9002 - recall_m: 0.8390 - val_loss: 0.3238 - val_acc: 0.9298 - val_f1_m: 0.9113 - val_precision_m: 0.9622 - val_recall_m: 0.8668\n","Epoch 2/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.3559 - acc: 0.8819 - f1_m: 0.8790 - precision_m: 0.9070 - recall_m: 0.8536 - val_loss: 0.2872 - val_acc: 0.9370 - val_f1_m: 0.9280 - val_precision_m: 0.9656 - val_recall_m: 0.8935\n","Epoch 3/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.3372 - acc: 0.8827 - f1_m: 0.8863 - precision_m: 0.9142 - recall_m: 0.8608 - val_loss: 0.2988 - val_acc: 0.9298 - val_f1_m: 0.9204 - val_precision_m: 0.9532 - val_recall_m: 0.8910\n","Epoch 4/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.3141 - acc: 0.8859 - f1_m: 0.8826 - precision_m: 0.9111 - recall_m: 0.8568 - val_loss: 0.2910 - val_acc: 0.9249 - val_f1_m: 0.9218 - val_precision_m: 0.9585 - val_recall_m: 0.8886\n","Epoch 5/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.2940 - acc: 0.8972 - f1_m: 0.9010 - precision_m: 0.9241 - recall_m: 0.8794 - val_loss: 0.2687 - val_acc: 0.9298 - val_f1_m: 0.9315 - val_precision_m: 0.9566 - val_recall_m: 0.9080\n","Epoch 6/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.3177 - acc: 0.8900 - f1_m: 0.8868 - precision_m: 0.9075 - recall_m: 0.8673 - val_loss: 0.2579 - val_acc: 0.9274 - val_f1_m: 0.9282 - val_precision_m: 0.9471 - val_recall_m: 0.9104\n","Epoch 7/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.3150 - acc: 0.8908 - f1_m: 0.8897 - precision_m: 0.9138 - recall_m: 0.8673 - val_loss: 0.2378 - val_acc: 0.9346 - val_f1_m: 0.9334 - val_precision_m: 0.9613 - val_recall_m: 0.9080\n","Epoch 8/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.3146 - acc: 0.8843 - f1_m: 0.8905 - precision_m: 0.9147 - recall_m: 0.8681 - val_loss: 0.2270 - val_acc: 0.9467 - val_f1_m: 0.9477 - val_precision_m: 0.9695 - val_recall_m: 0.9274\n","Epoch 9/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.2486 - acc: 0.9175 - f1_m: 0.9150 - precision_m: 0.9358 - recall_m: 0.8956 - val_loss: 0.1975 - val_acc: 0.9516 - val_f1_m: 0.9492 - val_precision_m: 0.9621 - val_recall_m: 0.9370\n","Epoch 10/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.3017 - acc: 0.8924 - f1_m: 0.8929 - precision_m: 0.9137 - recall_m: 0.8738 - val_loss: 0.2390 - val_acc: 0.9419 - val_f1_m: 0.9313 - val_precision_m: 0.9594 - val_recall_m: 0.9056\n","413/413 [==============================] - 1s 2ms/step\n","Training on Fold:  4\n","Train on 1236 samples, validate on 413 samples\n","Epoch 1/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.2796 - acc: 0.9094 - f1_m: 0.9099 - precision_m: 0.9269 - recall_m: 0.8940 - val_loss: 0.2461 - val_acc: 0.9443 - val_f1_m: 0.9301 - val_precision_m: 0.9565 - val_recall_m: 0.9056\n","Epoch 2/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.2406 - acc: 0.9150 - f1_m: 0.9188 - precision_m: 0.9349 - recall_m: 0.9037 - val_loss: 0.2146 - val_acc: 0.9516 - val_f1_m: 0.9473 - val_precision_m: 0.9555 - val_recall_m: 0.9395\n","Epoch 3/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.2246 - acc: 0.9215 - f1_m: 0.9219 - precision_m: 0.9352 - recall_m: 0.9094 - val_loss: 0.2174 - val_acc: 0.9492 - val_f1_m: 0.9475 - val_precision_m: 0.9534 - val_recall_m: 0.9419\n","Epoch 4/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.2459 - acc: 0.9150 - f1_m: 0.9166 - precision_m: 0.9310 - recall_m: 0.9029 - val_loss: 0.2208 - val_acc: 0.9492 - val_f1_m: 0.9540 - val_precision_m: 0.9801 - val_recall_m: 0.9298\n","Epoch 5/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.2359 - acc: 0.9199 - f1_m: 0.9229 - precision_m: 0.9365 - recall_m: 0.9102 - val_loss: 0.2165 - val_acc: 0.9322 - val_f1_m: 0.9416 - val_precision_m: 0.9600 - val_recall_m: 0.9249\n","Epoch 6/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.2354 - acc: 0.9223 - f1_m: 0.9216 - precision_m: 0.9335 - recall_m: 0.9102 - val_loss: 0.2029 - val_acc: 0.9637 - val_f1_m: 0.9594 - val_precision_m: 0.9679 - val_recall_m: 0.9516\n","Epoch 7/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.2128 - acc: 0.9239 - f1_m: 0.9224 - precision_m: 0.9352 - recall_m: 0.9102 - val_loss: 0.1956 - val_acc: 0.9613 - val_f1_m: 0.9543 - val_precision_m: 0.9653 - val_recall_m: 0.9443\n","Epoch 8/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.2117 - acc: 0.9239 - f1_m: 0.9211 - precision_m: 0.9325 - recall_m: 0.9102 - val_loss: 0.2215 - val_acc: 0.9492 - val_f1_m: 0.9467 - val_precision_m: 0.9649 - val_recall_m: 0.9298\n","Epoch 9/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.2054 - acc: 0.9272 - f1_m: 0.9308 - precision_m: 0.9406 - recall_m: 0.9215 - val_loss: 0.1908 - val_acc: 0.9637 - val_f1_m: 0.9570 - val_precision_m: 0.9654 - val_recall_m: 0.9492\n","Epoch 10/10\n","1236/1236 [==============================] - 9s 7ms/step - loss: 0.2206 - acc: 0.9312 - f1_m: 0.9293 - precision_m: 0.9411 - recall_m: 0.9183 - val_loss: 0.1808 - val_acc: 0.9661 - val_f1_m: 0.9593 - val_precision_m: 0.9751 - val_recall_m: 0.9443\n","413/413 [==============================] - 1s 2ms/step\n","test predictions  1.0\n","413/413 [==============================] - 1s 2ms/step\n","(0.9675382609517464, 0.9847316649577809, 0.9515738498789347, 1.0)\n","Model: \"model_20\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_20 (InputLayer)        (None, 64, 64, 3)         0         \n","_________________________________________________________________\n","conv2d_69 (Conv2D)           (None, 64, 64, 64)        1792      \n","_________________________________________________________________\n","max_pooling2d_69 (MaxPooling (None, 32, 32, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_70 (MaxPooling (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","dropout_74 (Dropout)         (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","conv2d_70 (Conv2D)           (None, 16, 16, 64)        36928     \n","_________________________________________________________________\n","conv2d_71 (Conv2D)           (None, 16, 16, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_71 (MaxPooling (None, 8, 8, 64)          0         \n","_________________________________________________________________\n","dropout_75 (Dropout)         (None, 8, 8, 64)          0         \n","_________________________________________________________________\n","flatten_20 (Flatten)         (None, 4096)              0         \n","_________________________________________________________________\n","dense_39 (Dense)             (None, 512)               2097664   \n","_________________________________________________________________\n","dropout_76 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_40 (Dense)             (None, 10)                5130      \n","=================================================================\n","Total params: 2,178,442\n","Trainable params: 2,178,442\n","Non-trainable params: 0\n","_________________________________________________________________\n","Training on Fold:  1\n","Train on 1236 samples, validate on 413 samples\n","Epoch 1/10\n","1236/1236 [==============================] - 14s 11ms/step - loss: 1.9629 - acc: 0.2856 - f1_m: 0.1390 - precision_m: 0.3289 - recall_m: 0.0939 - val_loss: 1.4429 - val_acc: 0.4818 - val_f1_m: 0.3212 - val_precision_m: 0.9102 - val_recall_m: 0.2010\n","Epoch 2/10\n","1236/1236 [==============================] - 10s 8ms/step - loss: 1.0453 - acc: 0.6505 - f1_m: 0.5981 - precision_m: 0.7973 - recall_m: 0.4911 - val_loss: 0.6881 - val_acc: 0.7579 - val_f1_m: 0.7616 - val_precision_m: 0.8768 - val_recall_m: 0.6755\n","Epoch 3/10\n","1236/1236 [==============================] - 10s 8ms/step - loss: 0.6267 - acc: 0.7880 - f1_m: 0.7879 - precision_m: 0.8595 - recall_m: 0.7306 - val_loss: 0.5120 - val_acc: 0.8547 - val_f1_m: 0.8350 - val_precision_m: 0.8914 - val_recall_m: 0.7869\n","Epoch 4/10\n","1236/1236 [==============================] - 10s 8ms/step - loss: 0.4481 - acc: 0.8463 - f1_m: 0.8516 - precision_m: 0.8957 - recall_m: 0.8131 - val_loss: 0.4268 - val_acc: 0.8692 - val_f1_m: 0.8644 - val_precision_m: 0.9112 - val_recall_m: 0.8232\n","Epoch 5/10\n","1236/1236 [==============================] - 10s 8ms/step - loss: 0.3983 - acc: 0.8600 - f1_m: 0.8647 - precision_m: 0.8989 - recall_m: 0.8341 - val_loss: 0.3674 - val_acc: 0.8814 - val_f1_m: 0.8839 - val_precision_m: 0.9074 - val_recall_m: 0.8620\n","Epoch 6/10\n","1236/1236 [==============================] - 10s 8ms/step - loss: 0.2668 - acc: 0.9070 - f1_m: 0.9079 - precision_m: 0.9273 - recall_m: 0.8900 - val_loss: 0.3525 - val_acc: 0.8838 - val_f1_m: 0.8884 - val_precision_m: 0.8983 - val_recall_m: 0.8789\n","Epoch 7/10\n","1236/1236 [==============================] - 11s 9ms/step - loss: 0.2375 - acc: 0.9231 - f1_m: 0.9254 - precision_m: 0.9425 - recall_m: 0.9094 - val_loss: 0.3352 - val_acc: 0.9031 - val_f1_m: 0.9020 - val_precision_m: 0.9136 - val_recall_m: 0.8910\n","Epoch 8/10\n","1236/1236 [==============================] - 10s 8ms/step - loss: 0.2045 - acc: 0.9337 - f1_m: 0.9332 - precision_m: 0.9472 - recall_m: 0.9199 - val_loss: 0.3343 - val_acc: 0.8983 - val_f1_m: 0.9019 - val_precision_m: 0.9108 - val_recall_m: 0.8935\n","Epoch 9/10\n","1236/1236 [==============================] - 10s 8ms/step - loss: 0.1882 - acc: 0.9450 - f1_m: 0.9437 - precision_m: 0.9561 - recall_m: 0.9320 - val_loss: 0.2526 - val_acc: 0.9128 - val_f1_m: 0.9113 - val_precision_m: 0.9252 - val_recall_m: 0.8983\n","Epoch 10/10\n","1236/1236 [==============================] - 11s 9ms/step - loss: 0.1451 - acc: 0.9515 - f1_m: 0.9506 - precision_m: 0.9589 - recall_m: 0.9426 - val_loss: 0.2538 - val_acc: 0.9298 - val_f1_m: 0.9315 - val_precision_m: 0.9408 - val_recall_m: 0.9225\n","413/413 [==============================] - 1s 2ms/step\n","Training on Fold:  2\n","Train on 1236 samples, validate on 413 samples\n","Epoch 1/10\n","1236/1236 [==============================] - 11s 9ms/step - loss: 0.1186 - acc: 0.9571 - f1_m: 0.9571 - precision_m: 0.9655 - recall_m: 0.9490 - val_loss: 0.2819 - val_acc: 0.9177 - val_f1_m: 0.9171 - val_precision_m: 0.9265 - val_recall_m: 0.9080\n","Epoch 2/10\n","1236/1236 [==============================] - 11s 9ms/step - loss: 0.1074 - acc: 0.9612 - f1_m: 0.9614 - precision_m: 0.9643 - recall_m: 0.9587 - val_loss: 0.2394 - val_acc: 0.9225 - val_f1_m: 0.9205 - val_precision_m: 0.9285 - val_recall_m: 0.9128\n","Epoch 3/10\n","1216/1236 [============================>.] - ETA: 0s - loss: 0.0907 - acc: 0.9663 - f1_m: 0.9697 - precision_m: 0.9750 - recall_m: 0.9646"],"name":"stdout"}]}]}